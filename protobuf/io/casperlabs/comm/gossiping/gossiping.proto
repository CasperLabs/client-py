syntax = "proto3";

package io.casperlabs.comm.gossiping;

import "google/protobuf/empty.proto";
import "io/casperlabs/casper/consensus/consensus.proto";
import "io/casperlabs/comm/discovery/node.proto";

service GossipService {
    // Notify the callee about new blocks being available on the caller.
    rpc NewBlocks(NewBlocksRequest) returns (NewBlocksResponse);

    // Notify the callee about new deploys being available on the caller.
    rpc NewDeploys(NewDeploysRequest) returns (NewDeploysResponse);

    // Retrieve the ancestors of certain blocks in the DAG; to be called repeatedly
    // as necessary to synchronize DAGs between peers.
    rpc StreamAncestorBlockSummaries(StreamAncestorBlockSummariesRequest) returns (stream io.casperlabs.casper.consensus.BlockSummary);

    // Retrieve latest messages as the callee knows them.
    rpc StreamLatestMessages(StreamLatestMessagesRequest) returns (stream io.casperlabs.casper.consensus.Block.Justification);

    // Retrieve arbitrary block summaries, if the callee knows about them.
    rpc StreamBlockSummaries(StreamBlockSummariesRequest) returns (stream io.casperlabs.casper.consensus.BlockSummary);

    // Retrieve arbitrary deploy summaries, if the callee knows about them.
    rpc StreamDeploySummaries(StreamDeploySummariesRequest) returns (stream io.casperlabs.casper.consensus.DeploySummary);

    // Retrieve an arbitrarily sized block as a stream of chunks, with optionally compressed content.
    rpc GetBlockChunked(GetBlockChunkedRequest) returns (stream Chunk);

    // Retrieve an arbitrary list of deploys, with optionally compressed contents.
    // One use case would be to gossip deploys between nodes so that they can be included
    // in a block by the first validator who gets to propose a block. The second case is
    // to retrieve all the deploys which are missing from the body of a block, i.e. haven't
    // been downloaded yet as part of earlier blocks or deploy gossiping.
    rpc StreamDeploysChunked(StreamDeploysChunkedRequest) returns (stream Chunk);

    // Retrieve the Genesis candidate supported by this node. Every node should either produce one from specification,
    // get one from its bootstrap, or have it persisted from earlier runs.
    // While the node is initializing and it hasn't obtained the candidate yet it will return UNAVAILABLE.
    // Once the node is serving a candidate identity, it should also be prepared to serve the full block on request.
    rpc GetGenesisCandidate(GetGenesisCandidateRequest) returns (io.casperlabs.casper.consensus.GenesisCandidate);

    // Add a signature to the list of approvals of a given candidate. If the block hash in the request doesn't match
    // the callee's candidate it will return INVALID_ARGUMENT, otherwise add the signature and forward it to its peers.
    rpc AddApproval(AddApprovalRequest) returns (google.protobuf.Empty);

    // Returns block summaries between two ranks (inclusive) in ascending topological order.
    // Used to gradually perform initial synchronization for new peers in the network.
    rpc StreamDagSliceBlockSummaries(StreamDagSliceBlockSummariesRequest) returns (stream io.casperlabs.casper.consensus.BlockSummary);
}

message NewBlocksRequest {
    // Address of the caller from where the callee can download the blocks from.
    io.casperlabs.comm.discovery.Node sender = 1;
    repeated bytes block_hashes = 2;
}

message NewBlocksResponse {
    // Indicate that some of the blocks in the notifications were new and the callee will attempt
    // to gossip them to further nodes when it gets around to downloading them.
    bool is_new = 1;
}

message NewDeploysRequest {
    // Address of the caller from where the callee can download the deploys from.
    io.casperlabs.comm.discovery.Node sender = 1;
    repeated bytes deploy_hashes = 2;
}

message NewDeploysResponse {
    // Indicate that some of the deploys in the notifications were new and the callee will attempt
    // to gossip them to further nodes when it gets around to downloading them.
    bool is_new = 1;
}

message StreamBlockSummariesRequest {
    repeated bytes block_hashes = 1;
}

message StreamDeploySummariesRequest {
    repeated bytes deploy_hashes = 1;
}

message StreamAncestorBlockSummariesRequest {
    // The identifiers of the blocks the caller wants to get to, typically the ones the callee notified
    // it about earlier, using `NewBlocks`.
    repeated bytes target_block_hashes = 1;

    // Supply the callee with some block hashes already known to the caller so the traversal can stop early if it hits them.
    // These can for example be the blocks last seen from each validator and the last finalized blocks.
    repeated bytes known_block_hashes = 2;

    // Limit the traversal to a certain depth, as a checkpoint when the caller can reassess and ask for
    // any hashes that still couldn't be connected to its own version of the DAG. If the target block
    // summaries are known then the value can be based on the difference in block sequence numbers between
    // the target and the last known block from the validator that produced it.
    // A value of -1 would mean no limit on the depth; 0 just returns the targets themselves.
    uint32 max_depth = 3;
}

message StreamLatestMessagesRequest {}

message GetBlockChunkedRequest {
    bytes block_hash = 1;
    uint32 chunk_size = 2;
    repeated string accepted_compression_algorithms = 3;
    // Download the processed deploys without their bodies.
    bool exclude_deploy_bodies = 4;
    // Download the processed deploys with only the hash, no body, header and approvals.
    bool only_include_deploy_hashes = 5;
}

message StreamDeploysChunkedRequest {
    repeated bytes deploy_hashes = 1;
    uint32 chunk_size = 2;
    repeated string accepted_compression_algorithms = 3;
}

message GetGenesisCandidateRequest {}

message AddApprovalRequest {
    // Hash of the candidate the caller supports.
    bytes block_hash = 1;
    io.casperlabs.casper.consensus.Approval approval = 2;
}

// Generic message for transferring a stream of data that wouldn't fit into single gRPC messages.
message Chunk {
    // Alternating between a header and subsequent chunks of data.
    oneof content {
        Header header = 1;
        bytes data = 2;
    }

    message Header {
        // Indicate if compression was used on the data. e.g. lz4
        string compression_algorithm = 1;
        // Use the `content_length` to sanity check the size of the data in the chunks that follow.
        uint32 content_length = 2;
        // The original content length before any compression was applied.
        uint32 original_content_length = 3;
    }
}

message StreamDagSliceBlockSummariesRequest {
    uint64 start_rank = 1;
    // Inclusive
    uint64 end_rank   = 2;
}
